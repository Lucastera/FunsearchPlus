{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ba1915fced4e72",
   "metadata": {},
   "source": [
    "# Run FunSearch on Bin Packing\n",
    "Five steps:\n",
    "1. Implement 'LLM' interface.\n",
    "2. Implement a 'SandBox' interface.\n",
    "3. Prepare a 'specification'.\n",
    "4. Prepare a dataset.\n",
    "5. Start FunSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d02b8e9c3ba67",
   "metadata": {},
   "source": [
    "## Preparation: download the project file from github. And update system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22453e8153e0934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/RayZhhh/funsearch.git\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/content/funsearch/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47175708cc0a93",
   "metadata": {},
   "source": [
    "## 1. Implement LLM interface\n",
    "Set the API's IP address according to your API provider (See line 65 in the following code).\n",
    "```python\n",
    "conn = http.client.HTTPSConnection(\"api.chatanywhere.com.cn\")\n",
    "```\n",
    "You should prepare a 'key' for the LLM API. And fill them in the header (See line 76-80 in the following code).\n",
    "```python\n",
    "headers = {\n",
    "    'Authorization': 'Bearer [put your key here, the key may start with \"sk-...\"]',\n",
    "    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1999e45c9a568b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import multiprocessing\n",
    "from typing import Collection, Any\n",
    "import http.client\n",
    "from implementation import sampler\n",
    "\n",
    "\n",
    "def _trim_preface_of_body(sample: str) -> str:\n",
    "    \"\"\"Trim the redundant descriptions/symbols/'def' declaration before the function body.\n",
    "    Please see my comments in sampler.LLM (in sampler.py).\n",
    "    Since the LLM used in this file is not a pure code completion LLM, this trim function is required.\n",
    "\n",
    "    -Example sample (function & description generated by LLM):\n",
    "    -------------------------------------\n",
    "    This is the optimized function ...\n",
    "    def priority_v2(...) -> ...:\n",
    "        return ...\n",
    "    This function aims to ...\n",
    "    -------------------------------------\n",
    "    -This function removes the description above the function's signature, and the function's signature.\n",
    "    -The indent of the code is preserved.\n",
    "    -Return of this function:\n",
    "    -------------------------------------\n",
    "        return ...\n",
    "    This function aims to ...\n",
    "    -------------------------------------\n",
    "    \"\"\"\n",
    "    lines = sample.splitlines()\n",
    "    func_body_lineno = 0\n",
    "    find_def_declaration = False\n",
    "    for lineno, line in enumerate(lines):\n",
    "        # find the first 'def' statement in the given code\n",
    "        if line[:3] == 'def':\n",
    "            func_body_lineno = lineno\n",
    "            find_def_declaration = True\n",
    "            break\n",
    "    if find_def_declaration:\n",
    "        code = ''\n",
    "        for line in lines[func_body_lineno + 1:]:\n",
    "            code += line + '\\n'\n",
    "        return code\n",
    "    return sample\n",
    "\n",
    "\n",
    "class LLMAPI(sampler.LLM):\n",
    "    \"\"\"Language model that predicts continuation of provided source code.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples_per_prompt: int, trim=True):\n",
    "        super().__init__(samples_per_prompt)\n",
    "        additional_prompt = ('Complete a different and more complex Python function. '\n",
    "                             'Be creative and you can insert multiple if-else and for-loop in the code logic.'\n",
    "                             'Only output the Python code, no descriptions.')\n",
    "        self._additional_prompt = additional_prompt\n",
    "        self._trim = trim\n",
    "\n",
    "    def draw_samples(self, prompt: str) -> Collection[str]:\n",
    "        \"\"\"Returns multiple predicted continuations of `prompt`.\"\"\"\n",
    "        return [self._draw_sample(prompt) for _ in range(self._samples_per_prompt)]\n",
    "\n",
    "    def _draw_sample(self, content: str) -> str:\n",
    "        prompt = '\\n'.join([content, self._additional_prompt])\n",
    "        while True:\n",
    "            try:\n",
    "                conn = http.client.HTTPSConnection(\"api.deepseek.com\")\n",
    "                payload = json.dumps({\n",
    "                    \"max_tokens\": 512,\n",
    "                    \"model\": \"deepseek-chat\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "                headers = {\n",
    "                    'Authorization': 'Bearer sk-4d4b1fb4def14ae3887a21683c3f1763',\n",
    "                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "                    'Content-Type': 'application/json'\n",
    "                }\n",
    "                conn.request(\"POST\", \"/v1/chat/completions\", payload, headers)\n",
    "                res = conn.getresponse()\n",
    "                data = res.read().decode(\"utf-8\")\n",
    "                data = json.loads(data)\n",
    "                response = data['choices'][0]['message']['content']\n",
    "                # trim function\n",
    "                if self._trim:\n",
    "                    response = _trim_preface_of_body(response)\n",
    "                return response\n",
    "            except Exception:\n",
    "                time.sleep(2)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27817cdec2cedfc",
   "metadata": {},
   "source": [
    "## 2. Implement a 'SandBox' interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e3d88a87535b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementation import evaluator\n",
    "from implementation import evaluator_accelerate\n",
    "\n",
    "\n",
    "class Sandbox(evaluator.Sandbox):\n",
    "    \"\"\"Sandbox for executing generated code. Implemented by RZ.\n",
    "\n",
    "    RZ: Sandbox returns the 'score' of the program and:\n",
    "    1) avoids the generated code to be harmful (accessing the internet, take up too much RAM).\n",
    "    2) stops the execution of the code in time (avoid endless loop).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=False, numba_accelerate=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            verbose         : Print evaluate information.\n",
    "            numba_accelerate: Use numba to accelerate the evaluation. It should be noted that not all numpy functions\n",
    "                              support numba acceleration, such as np.piecewise().\n",
    "        \"\"\"\n",
    "        self._verbose = verbose\n",
    "        self._numba_accelerate = numba_accelerate\n",
    "\n",
    "    def run(\n",
    "            self,\n",
    "            program: str,\n",
    "            function_to_run: str,  # RZ: refers to the name of the function to run (e.g., 'evaluate')\n",
    "            function_to_evolve: str,  # RZ: accelerate the code by decorating @numba.jit() on function_to_evolve.\n",
    "            inputs: Any,  # refers to the dataset\n",
    "            test_input: str,  # refers to the current instance\n",
    "            timeout_seconds: int,\n",
    "            **kwargs  # RZ: add this\n",
    "    ) -> tuple[Any, bool]:\n",
    "        \"\"\"Returns `function_to_run(test_input)` and whether execution succeeded.\n",
    "\n",
    "        RZ: If the generated code (generated by LLM) is executed successfully,\n",
    "        the output of this function is the score of a given program.\n",
    "        RZ: PLEASE NOTE THAT this SandBox is only designed for bin-packing problem.\n",
    "        \"\"\"\n",
    "        dataset = inputs[test_input]\n",
    "        try:\n",
    "            result_queue = multiprocessing.Queue()\n",
    "            process = multiprocessing.Process(\n",
    "                target=self._compile_and_run_function,\n",
    "                args=(program, function_to_run, function_to_evolve, dataset, self._numba_accelerate, result_queue)\n",
    "            )\n",
    "            process.start()\n",
    "            process.join(timeout=timeout_seconds)\n",
    "            if process.is_alive():\n",
    "                # if the process is not finished in time, we consider the program illegal\n",
    "                process.terminate()\n",
    "                process.join()\n",
    "                results = None, False\n",
    "            else:\n",
    "                if not result_queue.empty():\n",
    "                    results = result_queue.get_nowait()\n",
    "                else:\n",
    "                    results = None, False\n",
    "\n",
    "            return results\n",
    "        except:\n",
    "            return None, False\n",
    "\n",
    "    def _compile_and_run_function(self, program, function_to_run, function_to_evolve, dataset, numba_accelerate,\n",
    "                                  result_queue):\n",
    "        try:\n",
    "            # optimize the code (decorate function_to_run with @numba.jit())\n",
    "            if numba_accelerate:\n",
    "                program = evaluator_accelerate.add_numba_decorator(\n",
    "                    program=program,\n",
    "                    function_to_evolve=function_to_evolve\n",
    "                )\n",
    "            # compile the program, and maps the global func/var/class name to its address\n",
    "            all_globals_namespace = {}\n",
    "            # execute the program, map func/var/class to global namespace\n",
    "            exec(program, all_globals_namespace)\n",
    "            # get the pointer of 'function_to_run'\n",
    "            function_to_run = all_globals_namespace[function_to_run]\n",
    "            # return the execution results\n",
    "            results = function_to_run(dataset)\n",
    "            # the results must be int or float\n",
    "            if not isinstance(results, (int, float)):\n",
    "                result_queue.put((None, False))\n",
    "                return\n",
    "            result_queue.put((results, True))\n",
    "        except Exception:\n",
    "            # if raise any exception, we assume the execution failed\n",
    "            result_queue.put((None, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a05827354f9ae",
   "metadata": {},
   "source": [
    "## 3. Prepare a 'specification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2f875d128a693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "specification = r'''\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_valid_bin_indices(item: float, bins: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns indices of bins in which item can fit.\"\"\"\n",
    "    return np.nonzero((bins - item) >= 0)[0]\n",
    "\n",
    "\n",
    "def online_binpack(\n",
    "        items: tuple[float, ...], bins: np.ndarray\n",
    ") -> tuple[list[list[float, ...], ...], np.ndarray]:\n",
    "    \"\"\"Performs online binpacking of `items` into `bins`.\"\"\"\n",
    "    # Track which items are added to each bin.\n",
    "    packing = [[] for _ in bins]\n",
    "    # Add items to bins.\n",
    "    for item in items:\n",
    "        # Extract bins that have sufficient space to fit item.\n",
    "        valid_bin_indices = get_valid_bin_indices(item, bins)\n",
    "        # Score each bin based on heuristic.\n",
    "        priorities = priority(item, bins[valid_bin_indices])\n",
    "        # Add item to bin with highest priority.\n",
    "        best_bin = valid_bin_indices[np.argmax(priorities)]\n",
    "        bins[best_bin] -= item\n",
    "        packing[best_bin].append(item)\n",
    "    # Remove unused bins from packing.\n",
    "    packing = [bin_items for bin_items in packing if bin_items]\n",
    "    return packing, bins\n",
    "\n",
    "\n",
    "@funsearch.run\n",
    "def evaluate(instances: dict) -> float:\n",
    "    \"\"\"Evaluate heuristic function on a set of online binpacking instances.\"\"\"\n",
    "    # List storing number of bins used for each instance.\n",
    "    num_bins = []\n",
    "    # Perform online binpacking for each instance.\n",
    "    for name in instances:\n",
    "        instance = instances[name]\n",
    "        capacity = instance['capacity']\n",
    "        items = instance['items']\n",
    "        # Create num_items bins so there will always be space for all items,\n",
    "        # regardless of packing order. Array has shape (num_items,).\n",
    "        bins = np.array([capacity for _ in range(instance['num_items'])])\n",
    "        # Pack items into bins and return remaining capacity in bins_packed, which\n",
    "        # has shape (num_items,).\n",
    "        _, bins_packed = online_binpack(items, bins)\n",
    "        # If remaining capacity in a bin is equal to initial capacity, then it is\n",
    "        # unused. Count number of used bins.\n",
    "        num_bins.append((bins_packed != capacity).sum())\n",
    "    # Score of heuristic function is negative of average number of bins used\n",
    "    # across instances (as we want to minimize number of bins).\n",
    "    return -np.mean(num_bins)\n",
    "\n",
    "\n",
    "@funsearch.evolve\n",
    "def priority(item: float, bins: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns priority with which we want to add item to each bin.\n",
    "\n",
    "    Args:\n",
    "        item: Size of item to be added to the bin.\n",
    "        bins: Array of capacities for each bin.\n",
    "\n",
    "    Return:\n",
    "        Array of same size as bins with priority score of each bin.\n",
    "    \"\"\"\n",
    "    ratios = item / bins\n",
    "    log_ratios = np.log(ratios)\n",
    "    priorities = -log_ratios\n",
    "    return priorities\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bfe61e1661e18",
   "metadata": {},
   "source": [
    "## 4. Prepare a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fea85ccfc8c0ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bin_packing_utils\n",
    "\n",
    "bin_packing_or3 = {'OR3': bin_packing_utils.datasets['OR3']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66651fb2764ce9",
   "metadata": {},
   "source": [
    "## 5. Start FunSearch\n",
    "Please note that in jupyter notebook the following code will fail. This is because juypter does not support multiprocessing. Colab backend supports multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0ec0c796d09ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= Evaluated Function =================\n",
      "def priority(item: float, bins: np.ndarray) -> np.ndarray:\n",
      "    \"\"\"Returns priority with which we want to add item to each bin.\n",
      "\n",
      "    Args:\n",
      "        item: Size of item to be added to the bin.\n",
      "        bins: Array of capacities for each bin.\n",
      "\n",
      "    Return:\n",
      "        Array of same size as bins with priority score of each bin.\n",
      "    \"\"\"\n",
      "    ratios = item / bins\n",
      "    log_ratios = np.log(ratios)\n",
      "    priorities = -log_ratios\n",
      "    return priorities\n",
      "------------------------------------------------------\n",
      "Score        : None\n",
      "Sample time  : None\n",
      "Evaluate time: 0.09484410285949707\n",
      "Sample orders: None\n",
      "======================================================\n",
      "\n",
      "\n",
      "cluster_scores\n",
      "[]\n",
      "temperature\n",
      "0.1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Softmax received an empty array of logits. No clusters available.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mConfig(samples_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      9\u001b[0m global_max_sample_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# if it is set to None, funsearch will execute an endless loop\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mfunsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbin_packing_or3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_sample_nums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_max_sample_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../logs/funsearch_llm_api\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\SemesterB Assignment\\Artificial Intelligence\\Porject\\EoH\\baseline\\funsearch\\bin_packing\\implementation\\funsearch.py:109\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(specification, inputs, config, max_sample_nums, class_config, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# This loop can be executed in parallel on remote sampler machines. As each\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# sampler enters an infinite loop, without parallelization only the first\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# sampler will do any work.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m samplers:\n\u001b[1;32m--> 109\u001b[0m     \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\SemesterB Assignment\\Artificial Intelligence\\Porject\\EoH\\baseline\\funsearch\\bin_packing\\implementation\\sampler.py:97\u001b[0m, in \u001b[0;36mSampler.sample\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_sample_nums \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m_global_samples_nums \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_sample_nums:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m reset_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     99\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mdraw_samples(prompt\u001b[38;5;241m.\u001b[39mcode)\n",
      "File \u001b[1;32mD:\\SemesterB Assignment\\Artificial Intelligence\\Porject\\EoH\\baseline\\funsearch\\bin_packing\\implementation\\programs_database.py:134\u001b[0m, in \u001b[0;36mget_prompt\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \"\"\"Returns a prompt containing implementations from one chosen island.\"\"\"\n\u001b[0;32m    133\u001b[0m island_id = np.random.randint(len(self._islands))\n\u001b[1;32m--> 134\u001b[0m code, version_generated = self._islands[island_id].get_prompt()\n\u001b[0;32m    135\u001b[0m return Prompt(code, version_generated, island_id)\n\u001b[0;32m    136\u001b[0m \n",
      "File \u001b[1;32mD:\\SemesterB Assignment\\Artificial Intelligence\\Porject\\EoH\\baseline\\funsearch\\bin_packing\\implementation\\programs_database.py:260\u001b[0m, in \u001b[0;36mget_prompt\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m print('temperature')\n\u001b[0;32m    259\u001b[0m print(temperature)\n\u001b[1;32m--> 260\u001b[0m probabilities = _softmax(cluster_scores, temperature)\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m # At the beginning of an experiment when we have few clusters, place fewer\n",
      "File \u001b[1;32mD:\\SemesterB Assignment\\Artificial Intelligence\\Porject\\EoH\\baseline\\funsearch\\bin_packing\\implementation\\programs_database.py:59\u001b[0m, in \u001b[0;36m_softmax\u001b[1;34m(logits, temperature)\u001b[0m\n\u001b[0;32m     57\u001b[0m \"\"\"Returns the tempered softmax of 1D finite `logits`.\"\"\"\n\u001b[0;32m     58\u001b[0m if len(logits) == 0:\n\u001b[1;32m---> 59\u001b[0m     raise ValueError(\"Softmax received an empty array of logits. No clusters available.\")\n\u001b[0;32m     60\u001b[0m if not np.all(np.isfinite(logits)):\n\u001b[0;32m     61\u001b[0m     non_finites = set(logits[~np.isfinite(logits)])\n",
      "\u001b[1;31mValueError\u001b[0m: Softmax received an empty array of logits. No clusters available."
     ]
    }
   ],
   "source": [
    "from implementation import funsearch\n",
    "from implementation import config\n",
    "\n",
    "# It should be noted that the if __name__ == '__main__' is required.\n",
    "# Because the inner code uses multiprocess evaluation.\n",
    "if __name__ == '__main__':\n",
    "    class_config = config.ClassConfig(llm_class=LLMAPI, sandbox_class=Sandbox)\n",
    "    config = config.Config(samples_per_prompt=4)\n",
    "    global_max_sample_num = 10  # if it is set to None, funsearch will execute an endless loop\n",
    "    funsearch.main(\n",
    "        specification=specification,\n",
    "        inputs=bin_packing_or3,\n",
    "        config=config,\n",
    "        max_sample_nums=global_max_sample_num,\n",
    "        class_config=class_config,\n",
    "        log_dir='../logs/funsearch_llm_api'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7626fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_project]",
   "language": "python",
   "name": "conda-env-ai_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
